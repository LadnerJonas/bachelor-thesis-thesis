\chapter{\abstractname}

Modern streaming database systems rely on efficient data partitioning to achieve scalability and high performance across processing nodes.
Partitioned data shuffling is a crucial operation, as it is used to prepare and distribute data for further processing on distributed systems.

This thesis purposes and evaluates various partitioning implementations by simulating real-world usage of the shuffle operator.
The implementations process incoming tuple batches and partition them into output buckets, which are based on slotted pages and can be passed to subsequent operators.
The evaluation of the implementations is based on their performance, scalability and memory consumption.

We evaluate 10 shuffle operator implementations and identify two highly efficient approaches: (1) thread-local slotted pages with merging, optimal for fewer than 32 partitions, and (2) a group of \ac{SMB} implementations excelling beyond 16 partitions.
Throughput and scalability analyses show that the thread-local slotted page approach achieves up to 2.1x higher performance for low partition counts, while the \ac{SMB} group scales efficiently, outperforming other methods by 2.4x for high partition counts.
