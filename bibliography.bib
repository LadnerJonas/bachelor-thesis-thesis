@article{radix-partitioning-case,
  title        = {On the surprising difficulty of simple things: the case of radix partitioning},
  author       = {Schuhknecht, Felix Martin and Khanchandani, Pankaj and Dittrich, Jens},
  year         = 2015,
  month        = may,
  journal      = {Proc. VLDB Endow.},
  publisher    = {VLDB Endowment},
  volume       = 8,
  number       = 9,
  pages        = {934–937},
  doi          = {10.14778/2777598.2777602},
  issn         = {2150-8097},
  url          = {https://doi.org/10.14778/2777598.2777602},
  issue_date   = {May 2015},
  abstract     = {Partitioning a dataset into ranges is a task that is common in various applications such as sorting [1,6,7,8,9] and hashing [3] which are in turn building blocks for almost any type of query processing. Especially radix-based partitioning is very popular due to its simplicity and high performance over comparison-based versions [6].},
  numpages     = 4
}
@inproceedings{join-processing-in-parallel-db,
  title        = {From Theory to Practice: Efficient Join Query Evaluation in a Parallel Database System},
  author       = {Chu, Shumo and Balazinska, Magdalena and Suciu, Dan},
  year         = 2015,
  booktitle    = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
  location     = {Melbourne, Victoria, Australia},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  series       = {SIGMOD '15},
  pages        = {63–78},
  doi          = {10.1145/2723372.2750545},
  isbn         = 9781450327589,
  url          = {https://doi.org/10.1145/2723372.2750545},
  abstract     = {Big data analytics often requires processing complex queries using massive parallelism, where the main performance metrics is the communication cost incurred during data reshuffling. In this paper, we describe a system that can compute efficiently complex join queries, including queries with cyclic joins, on a massively parallel architecture. We build on two independent lines of work for multi-join query evaluation: a communication-optimal algorithm for distributed evaluation, and a worst-case optimal algorithm for sequential evaluation. We evaluate these algorithms together, then describe novel, practical optimizations for both algorithms.},
  numpages     = 16,
  keywords     = {parallel database system, join query evaluation}
}
@inproceedings{main-memory-partitioning,
  title        = {A comprehensive study of main-memory partitioning and its application to large-scale comparison- and radix-sort},
  author       = {Polychroniou, Orestis and Ross, Kenneth A.},
  year         = 2014,
  booktitle    = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
  location     = {Snowbird, Utah, USA},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  series       = {SIGMOD '14},
  pages        = {755–766},
  doi          = {10.1145/2588555.2610522},
  isbn         = 9781450323765,
  url          = {https://doi.org/10.1145/2588555.2610522},
  abstract     = {Analytical database systems can achieve high throughput main-memory query execution by being aware of the dynamics of highly-parallel modern hardware. Such systems rely on partitioning to cluster or divide data into smaller pieces and thus achieve better parallelism and memory locality. This paper considers a comprehensive collection of variants of main-memory partitioning tuned for various layers of the memory hierarchy. We revisit the pitfalls of in-cache partitioning, and utilizing the crucial performance factors, we introduce new variants for partitioning out-of-cache. Besides non-in-place variants where linear extra space is used, we introduce large-scale in-place variants, and propose NUMA-aware partitioning that guarantees locality on multiple processors. Also, we make range partitioning comparably fast with hash or radix, by designing a novel cache-resident index to compute ranges. All variants are combined to build three NUMA-aware sorting algorithms: a stable LSB radix-sort; an in-place MSB radix-sort using different variants across memory layers; and a comparison-sort utilizing wide-fanout range partitioning and SIMD-optimal in-cache sorting. To the best of our knowledge, all three are the fastest to date on billion-scale inputs for both dense and sparse key domains. As shown for sorting, our work can serve as a tool for building other operations (e.g., join, aggregation) by combining the most suitable variants that best meet the design goals.},
  numpages     = 12,
  keywords     = {NUMA, SIMD, multi-core, parallelism, partitioning, sorting}
}
@inproceedings{data-partitioning-in-memory-systems,
  title        = {Data Partitioning for In-Memory Systems: Myths, Challenges, and Opportunities},
  author       = {Zhang, Zuyu and Deshmukh, Harshad and Patel, Jignesh M.},
  year         = 2019,
  booktitle    = {Proceedings of the 9th Biennial Conference on Innovative Data Systems Research (CIDR 2019)},
  publisher    = {CIDR},
  address      = {Chaminade, CA, USA},
  url          = {https://www.cidrdb.org/cidr2019/papers/p133-zhang-cidr19.pdf}
}
@inproceedings{locality-aware-partitioning-in-parallel-db,
  title        = {Locality-aware Partitioning in Parallel Database Systems},
  author       = {Zamanian, Erfan and Binnig, Carsten and Salama, Abdallah},
  year         = 2015,
  booktitle    = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
  location     = {Melbourne, Victoria, Australia},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  series       = {SIGMOD '15},
  pages        = {17–30},
  doi          = {10.1145/2723372.2723718},
  isbn         = 9781450327589,
  url          = {https://doi.org/10.1145/2723372.2723718},
  abstract     = {Parallel database systems horizontally partition large amounts of structured data in order to provide parallel data processing capabilities for analytical workloads in shared-nothing clusters. One major challenge when horizontally partitioning large amounts of data is to reduce the network costs for a given workload and a database schema. A common technique to reduce the network costs in parallel database systems is to co-partition tables on their join key in order to avoid expensive remote join operations. However, existing partitioning schemes are limited in that respect since only subsets of tables in complex schemata sharing the same join key can be co-partitioned unless tables are fully replicated.In this paper we present a novel partitioning scheme called predicate-based reference partition (or PREF for short) that allows to co-partition sets of tables based on given join predicates. Moreover, based on PREF, we present two automatic partitioning design algorithms to maximize data-locality. One algorithm only needs the schema and data whereas the other algorithm additionally takes the workload as input. In our experiments we show that our automated design algorithms can partition database schemata of different complexity and thus help to effectively reduce the runtime of queries under a given workload when compared to existing partitioning approaches.},
  numpages     = 14,
  keywords     = {partitioning schemes}
}
@article{RDMA-aware-Data-Shuffling-Operator,
  title        = {Design and Evaluation of an RDMA-aware Data Shuffling Operator for Parallel Database Systems},
  author       = {Liu, Feilong and Yin, Lingyan and Blanas, Spyros},
  year         = 2019,
  month        = dec,
  journal      = {ACM Trans. Database Syst.},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  volume       = 44,
  number       = 4,
  doi          = {10.1145/3360900},
  issn         = {0362-5915},
  url          = {https://doi.org/10.1145/3360900},
  issue_date   = {December 2019},
  abstract     = {The commoditization of high-performance networking has sparked research interest in the RDMA capability of this hardware. One-sided RDMA primitives, in particular, have generated substantial excitement due to the ability to directly access remote memory from within an application without involving the TCP/IP stack or the remote CPU. This article considers how to leverage RDMA to improve the analytical performance of parallel database systems. To shuffle data efficiently using RDMA, one needs to consider a complex design space that includes (1) the number of open connections, (2) the contention for the shared network interface, (3) the RDMA transport function, and (4) how much memory should be reserved to exchange data between nodes during query processing. We contribute eight designs that capture salient tradeoffs in this design space as well as an adaptive algorithm to dynamically manage RDMA-registered memory. We comprehensively evaluate how transport-layer decisions impact the query performance of a database system for different generations of InfiniBand. We find that a shuffling operator that uses the RDMA Send/Receive transport function over the Unreliable Datagram transport service can transmit data up to 4\texttimes{} faster than an RDMA-capable MPI implementation in a 16-node cluster. The response time of TPC-H queries improves by as much as 2\texttimes{}.},
  articleno    = 17,
  numpages     = 45,
  keywords     = {parallel database systems, RDMA, Data shuffling}
}
@inproceedings{main-memory-partitioning-study,
  title        = {A comprehensive study of main-memory partitioning and its application to large-scale comparison- and radix-sort},
  author       = {Polychroniou, Orestis and Ross, Kenneth A.},
  year         = 2014,
  booktitle    = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
  location     = {Snowbird, Utah, USA},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  series       = {SIGMOD '14},
  pages        = {755–766},
  doi          = {10.1145/2588555.2610522},
  isbn         = 9781450323765,
  url          = {https://doi.org/10.1145/2588555.2610522},
  abstract     = {Analytical database systems can achieve high throughput main-memory query execution by being aware of the dynamics of highly-parallel modern hardware. Such systems rely on partitioning to cluster or divide data into smaller pieces and thus achieve better parallelism and memory locality. This paper considers a comprehensive collection of variants of main-memory partitioning tuned for various layers of the memory hierarchy. We revisit the pitfalls of in-cache partitioning, and utilizing the crucial performance factors, we introduce new variants for partitioning out-of-cache. Besides non-in-place variants where linear extra space is used, we introduce large-scale in-place variants, and propose NUMA-aware partitioning that guarantees locality on multiple processors. Also, we make range partitioning comparably fast with hash or radix, by designing a novel cache-resident index to compute ranges. All variants are combined to build three NUMA-aware sorting algorithms: a stable LSB radix-sort; an in-place MSB radix-sort using different variants across memory layers; and a comparison-sort utilizing wide-fanout range partitioning and SIMD-optimal in-cache sorting. To the best of our knowledge, all three are the fastest to date on billion-scale inputs for both dense and sparse key domains. As shown for sorting, our work can serve as a tool for building other operations (e.g., join, aggregation) by combining the most suitable variants that best meet the design goals.},
  numpages     = 12,
  keywords     = {NUMA, SIMD, multi-core, parallelism, partitioning, sorting}
}
@inproceedings{Micro-Partitioning,
  title        = {Micro Partitioning: Friendly to the Hardware and the Developer},
  author       = {M\"{u}hlig, Jan and Teubner, Jens},
  year         = 2023,
  booktitle    = {Proceedings of the 19th International Workshop on Data Management on New Hardware},
  location     = {Seattle, WA, USA},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  series       = {DaMoN '23},
  pages        = {27–34},
  doi          = {10.1145/3592980.3595310},
  isbn         = 9798400701917,
  url          = {https://doi.org/10.1145/3592980.3595310},
  abstract     = {Modern hardware’s complexity has made studying hardware-conscious algorithms a relevant topic for many years. Partitioning algorithms, for instance, break data into bits that fit into fast CPU caches. Unfortunately, they are often challenging to design, develop, and maintain. While hardware-oblivious algorithms are easier to build, they may perform poorly when hardware or data deviate from expectations. In this paper, we introduce micro partitioning, which enhances the partitioning problem in a way that outperforms state-of-the-art solutions while being hardware-agnostic. By storing tuples in a tight address space, micro partitioning creates an access pattern that is friendly to both caches and translation lookaside buffers. We also show how micro partitioning interacts with task-based execution strategies in a symbiotic way, making micro partitioning intuitive to express for developers.},
  numpages     = 8
}
